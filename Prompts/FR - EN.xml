<?xml version="1.0"?>
<OpenAI xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema">
  <prompt>
    <!--
        Le promt <system> est très important et necessite que vous l'écriviez avec soin. Il permet à l'assistant de comprendre ce qu'il doit faire, comment il doit se comporter, ce qu'il doit répondre à vos requettes et sous quelle forme, etc... Si vous voulez que le plugin renvoi à VoiceAttack une commande à executer, c'est ici que ca se joue.
        
        Dans l'exemple donné ci-dessous, il est demandé à l'assistant de répondre toujours par un seul mot (la REPONSE) qui est donné dans une liste de possibilités listées entre (). A charge pour l'assitant de comprendre ce que vous voulez et de renvoyer la bonne commande (c'est fait par un appel aux API OpenAI avec les modèles GPT-3 ou GPT-4, que vous pouvez configurer dans params.xml)
        
        Vous devez lui proposer des commandes qui ont toutes le même prefix ("API_" dans l'exemple ci dessous) de manière à ce que le plugin puisse reconnaitre si l'assistant a bien répondu une commande, ou autre chose !
        Le prefixe est configurable plus bas (voir <command_prefix>)
        
        Le plugin va donc rechercher un mot commencant par le prefixe dans la réponse de l'assistant et, si il le trouve, va considérer que c'est la commande à retourner à Voiceattack. Si vous le souhaitez (voir <ignore_answer_text> plus bas) le reste de la réponse sera transformé en fichier audio et envoyé à vos écouteurs.
        -->
    <system>Tu traduis les phrases en anglais.
Si tu ne trouves pas de phrase à traduire, tu réponds par "..."</system>
    <!--
        Les tags <user_request_exemple> et <assist_answer_exemple> aident l'assistant à comprendre le format d'un échange. vous devez donner ici un exemple de requette et la réponse attendue pour cette requette.
        -->
    <user_request_exemple>
    </user_request_exemple>
    <assist_answer_exemple>
    </assist_answer_exemple>
    <!--
        Liberté de réponse (0 réponse strict à 20 inventif)
        -->
    <answer_temperature>0</answer_temperature>
    <!--
        <command_prefix> est le moyen pour le plugin de reconnaitre ce qu'est une commande dans la réponse de l'assistant.
        Dans votre promt <system> vous devez expliquer à l'assistant qu'il doit répondre avec des commandes qui commencent par ce prefix.
        -->
    <command_prefix>
    </command_prefix>
    <!--
       Si la réponse de l'assistant contient du texte en plus d'une commande (voir même si il ne contient pas de commande)
        le plugin va transformer ce texte avec un appel aux API OpenAI text-to-speech puis envoyer l'audio dans vos écouteurs.
        Cette étape est potentiellement couteuse en terme de token, et augmente le temps d'attente de la réponse.
        Vous pouvez l'éviter en mettant ici la valeur à 1, 2 ou 3. Dans ce cas, l'assistant restera silencieux... (mais les commandes seront reconnues et executées).
        Valeurs possibles :
        0 - le texte est simplement ignoré
        1 - le plugin copie le texte dans le presse-papier et renvoi une commande "TO_CLIPBOARD" précédé du prefix de commande. Exemple "API_TO_CLIPBOARD"
        2 - le plugin copie le texte dans un token {EliteAssistantResult} et renvoi une commande "TO_TOKEN" précédé du prefix de commande. Exemple "API_TO_TOKEN"
        3 - le plugin envoi le texte dans les écouteurs
        -->
    <process_answer_text>1</process_answer_text>
    <!--
        Si votre requette contient moins de <speech_lenght_min> caractères, elle ne sera pas prise en compte par le plugin. Ceci est fait pour éviter de traiter des petits bruits involontaires qui pourraient être captés par votre micro.
        -->
    <speech_lenght_min>0</speech_lenght_min>
    <!--
        Vous pouvez demander à éliminer de la réponse de l'assistant tous les mots appartenant à cette liste de mots séparés par des ';'. Le test ne prends pas en compte la casse.
        -->
    <remove_words>
    </remove_words>
    <!--
        <chat_buffer_size> vous permet de ré-injecter dans chaque requette vos derniers échanges avec l'assistant. Le but est d'avoir un minimum de suivi dans votre échange avec l'assistant, par exemple si vous souhaitez parler avec lui
        en plus des requettes de commandes. Si votre prompt <system> fait que l'assistant ne retourne que des commandes, avoir un suivi de la conversation a peu d'interêt et vous devriez laisser cette valeur à 0.
        
        Si la valeur est 0, chaque requette va créer une nouvelle conversation avec le minimum requis, à savoir :
        * The <system> promp
        * The <user_request_exemple>
        * The <assist_answer_exemple>
        * Your request
        
        Si vous augmentez cette valeur, le plugin va ajouter à la conversation autant de couple (resquests + answers) issus de vos conversations précédantes dans la nouvelle conversation. Ainsi, si par exemple vous mettez 1, chaque requette donnera lieu à une conversation avec :
        * The <system> promp
        * The <user_request_exemple> text
        * The <assist_answer_exemple> text
        * the previous request you made
        * the previous assitant answer
        * Your new request
        -->
    <chat_buffer_size>0</chat_buffer_size>
    <tts_voice>echo</tts_voice>
    <tts_voice_ext>0</tts_voice_ext>
    <assistant_model>gpt-4o</assistant_model>
    <tts_voice_ext_device>00000000-0000-0000-0000-000000000000</tts_voice_ext_device>
    <user_langage>fr</user_langage>
  </prompt>
</OpenAI>